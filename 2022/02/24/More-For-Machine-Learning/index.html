<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="Jerry Ren"><meta name="copyright" content="Jerry Ren"><title>JERRY's blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  hexoVersion: '5.4.0'
} </script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="JERRY's blog" type="application/atom+xml">
</head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#KMeans%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E8%81%9A%E7%B1%BB%EF%BC%9A"><span class="toc-number">1.</span> <span class="toc-text">KMeans实现数据聚类：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KMeans%E5%AE%9E%E7%8E%B0%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%EF%BC%9A"><span class="toc-number">2.</span> <span class="toc-text">KMeans实现图像分割：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%82%E5%B8%B8%E6%B6%88%E8%B4%B9%E8%A1%8C%E4%B8%BA%E6%A3%80%E6%B5%8B%EF%BC%9A"><span class="toc-number">3.</span> <span class="toc-text">异常消费行为检测：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#PCA-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%A3%80%E6%9F%A5%E8%80%85%E6%98%AF%E5%90%A6%E6%82%A3%E7%B3%96%E5%B0%BF%E7%97%85"><span class="toc-number">4.</span> <span class="toc-text">PCA+逻辑回归预测检查者是否患糖尿病</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="/img/avatar.png"></div><div class="author-info__name text-center">Jerry Ren</div><div class="author-info__description text-center"></div><div class="follow-button"><a target="_blank" rel="noopener" href="https://github.com/USERNAME">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">5</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimg.jj20.com%2Fup%2Fallimg%2F1114%2F123020113951%2F201230113951-1-1200.jpg&amp;refer=http%3A%2F%2Fimg.jj20.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1644738157&amp;t=0a3e38ccf19424d69fb8678eb1bf7a75.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">JERRY's blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">No title</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2022-02-24</time></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>在上一章博客中我们学习到了一些基本的机器学习的分类计算模型，接下来我们将进行更加深入的学习。</p>
<p><strong>无监督学习</strong>：机器学习的一种方法，训练数据中不带标签，让机器自动寻找数据规律并完成任务。</p>
<p>特点：</p>
<ol>
<li>数据不需要标签。</li>
<li>算法不受监督信息约束。</li>
</ol>
<p>优点：</p>
<ol>
<li>降低数据采集难度，极大程度扩充样本量。</li>
<li>可能发现新的数据规律、被忽略的重要信息。</li>
</ol>
<p><strong>聚类分析</strong>：把数据样本按照一定的方法分成不同的组别，这样让在同一个组别中的成员对象都有相似的一些属性。</p>
<p><strong>K均值聚类</strong>：在样本数据空间中选取K个点作为中心，计算每个样本到各中心的距离，根据距离确定数据类别，是聚类算法中最为基础但也最为重要的算法。</p>
<p><strong>核心流程</strong>：</p>
<ol>
<li>基于要求，观察或经验确定聚类的个数K.</li>
<li>确定K个中心。</li>
<li>计算样本到各中心点距离。</li>
<li>根据距离确定各个样本点所属类别。</li>
<li>计算同类别样本的中心点，并将其设定为新的中心。</li>
<li>重复步骤3-5直到收敛(中心点不再变化)。</li>
</ol>
<p>通过K均值聚类可以实现<strong>图像分割</strong>，<strong>图像分割</strong>就是把图像分成若干个特定的、具有独特性质的区域的技术，是由图像处理到图像分析的关键步骤。</p>
<h4 id="KMeans实现数据聚类："><a href="#KMeans实现数据聚类：" class="headerlink" title="KMeans实现数据聚类："></a>KMeans实现数据聚类：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data=pd.read_csv(<span class="string">&#x27;task1_data1.csv&#x27;</span>)<span class="comment">#测试样本</span></span><br><span class="line">data_result=pd.read_csv(<span class="string">&#x27;task1_data2.csv&#x27;</span>)<span class="comment">#检验</span></span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220225111032327.png" alt="image-20220225111032327"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取唯一一个有标签的数据点</span></span><br><span class="line">x_labeled=data.iloc[<span class="number">0</span>,:]<span class="comment">#取第0行的所有数据</span></span><br><span class="line"><span class="built_in">print</span>(x_labeled)</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220225111138082.png" alt="image-20220225111138082"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#x赋值</span></span><br><span class="line">x=data.drop[<span class="string">&#x27;y&#x27;</span>,axis=<span class="number">1</span>]</span><br><span class="line"><span class="comment">#正确结果的赋值</span></span><br><span class="line">y=data_result.loc[;,<span class="string">&#x27;y&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据可视化</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig1=plt.figure()</span><br><span class="line">plt.scatter(x.loc[:,<span class="string">&#x27;x1&#x27;</span>],x.loc[:<span class="string">&#x27;x2&#x27;</span>],label=<span class="string">&#x27;unlabeled&#x27;</span>)</span><br><span class="line">plt.scatter(x_labeled[<span class="string">&#x27;x1&#x27;</span>],x_labeled[<span class="string">&#x27;x2&#x27;</span>]，label=<span class="string">&#x27;labeled&#x27;</span>)<span class="comment">#格式不同，取点方式也不同</span></span><br><span class="line">plt.title(<span class="string">&#x27;unlabeled data&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)<span class="comment">#移动至左上角</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220225112243062.png" alt="image-20220225112243062"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#建立KMeans模型并训练</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">KM=KMeans(n_clusters=<span class="number">2</span>,init=<span class="string">&#x27;random&#x27;</span>,random_state=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#训练</span></span><br><span class="line">KM.fit(x)<span class="comment">#无监督，不用训练y</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看聚类中心</span></span><br><span class="line">centers=KM.cluster_centers_</span><br><span class="line"></span><br><span class="line"><span class="comment">#画中心点</span></span><br><span class="line">plt.scatter(centers[:,<span class="number">0</span>],centers[:,<span class="number">1</span>],<span class="number">100</span>,marker=<span class="string">&#x27;x&#x27;</span>,label=<span class="string">&#x27;centers&#x27;</span>)<span class="comment">#设置大小和标记</span></span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220225203120993.png" alt="image-20220225203120993"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#无监督聚类结果预测</span></span><br><span class="line">y_predict=KM.predict(x)</span><br><span class="line"><span class="built_in">print</span>(pd.value_counts(y_predict)<span class="comment">#统计1和0的数量</span></span><br><span class="line"><span class="built_in">print</span>(pd.value_counts(y))</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220225203751535.png" alt="image-20220225203751535"></p>
<p>由测试数集可以看出，聚类预测的结果由较大的偏差，但也不难看出，可能在分析时，将1和0的分类有可能分反了，因此：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#结果矫正</span></span><br><span class="line">y_corrected=[]<span class="comment">#创建一个新的列表</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> y_predict:</span><br><span class="line">    <span class="keyword">if</span> i==<span class="number">0</span>:</span><br><span class="line">        y_corrected.append(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">elif</span> i==<span class="number">1</span>:</span><br><span class="line">        y_corrected.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化</span></span><br><span class="line">y_corrected=np.array(y_corrected)<span class="comment">#转化格式用于画图索引</span></span><br><span class="line">fig2=plt.figure(figsize=(<span class="number">16</span>,<span class="number">8</span>)<span class="comment">#设定图片大小</span></span><br><span class="line"></span><br><span class="line">fig3=plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.scatter(x.loc[:,<span class="string">&#x27;x1&#x27;</span>][y_corrected==<span class="number">0</span>],x.loc[:<span class="string">&#x27;x2&#x27;</span>][y_corrected==<span class="number">0</span>],label=<span class="string">&#x27;label0&#x27;</span>)</span><br><span class="line">plt.scatter(x_labeled[<span class="string">&#x27;x1&#x27;</span>][y_corrected==<span class="number">1</span>],x_labeled[<span class="string">&#x27;x2&#x27;</span>][y_corrected==<span class="number">1</span>]，label=<span class="string">&#x27;label1&#x27;</span>)</span><br><span class="line">plt.scatter(x_labeled[<span class="string">&#x27;x1&#x27;</span>],x_labeled[<span class="string">&#x27;x2&#x27;</span>],label=<span class="string">&#x27;labeled&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;unlabeled data(corrected result)&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)<span class="comment">#移动至左上角</span></span><br><span class="line"></span><br><span class="line">fig4=plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.scatter(x.loc[:,<span class="string">&#x27;x1&#x27;</span>][y==<span class="number">0</span>],x.loc[:<span class="string">&#x27;x2&#x27;</span>][y==<span class="number">0</span>],label=<span class="string">&#x27;label0&#x27;</span>)</span><br><span class="line">plt.scatter(x_labeled[<span class="string">&#x27;x1&#x27;</span>][y==<span class="number">1</span>],x_labeled[<span class="string">&#x27;x2&#x27;</span>][y==<span class="number">1</span>]，label=<span class="string">&#x27;label1&#x27;</span>)</span><br><span class="line">plt.scatter(x_labeled[<span class="string">&#x27;x1&#x27;</span>],x_labeled[<span class="string">&#x27;x2&#x27;</span>],label=<span class="string">&#x27;labeled&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;labeled data&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;x2&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper left&#x27;</span>)<span class="comment">#移动至左上角</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220225210356372.png" alt="image-20220225210356372"></p>
<p>接下来，我们运用KNN算法进行建模并于之前的方法进行比较：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#knn建模与训练</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">knn=KNeighborsClassifier(n_neighbors=<span class="number">3</span>)<span class="comment">#设置k=3</span></span><br><span class="line">knn.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型预测</span></span><br><span class="line">y_predict_knn=knn.predict(x)</span><br><span class="line"><span class="comment">#通过计算准确率有1.0预测效果好。</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#KMeans迭代一次的结果</span></span><br><span class="line">KM2=KMeans(n_clusters=<span class="number">2</span>,init=<span class="string">&#x27;random&#x27;</span>,random_state=<span class="number">1</span>,n_init=<span class="number">1</span>,max_iter=<span class="number">1</span>)</span><br><span class="line">KM2.fix(x)</span><br><span class="line">centers=KM2.clusters_centers</span><br><span class="line">y_predict2=KM2.predict(x)</span><br></pre></td></tr></table></figure>

<h4 id="KMeans实现图像分割："><a href="#KMeans实现图像分割：" class="headerlink" title="KMeans实现图像分割："></a>KMeans实现图像分割：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#图像的加载与展示</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io <span class="keyword">as</span> io</span><br><span class="line">img=io.read(<span class="string">&#x27;1.jpg&#x27;</span>)</span><br><span class="line">plt.show(img.)</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220227212737932.png" alt="image-20220227212737932"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#维度存储</span></span><br><span class="line">img_height=img.shape[<span class="number">0</span>]</span><br><span class="line">img_width=img.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据维度转化</span></span><br><span class="line">img_data=img.reshape(-<span class="number">1</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#x赋值</span></span><br><span class="line">x=img_data</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型建立与训练</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line">model=KMeans(n_clusters=<span class="number">3</span>,random_state=<span class="number">0</span>)</span><br><span class="line">model.fit(x)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#聚类结果预测</span></span><br><span class="line">label=model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#结果数据的维度转化</span></span><br><span class="line">label=label.reshape([img_height,img_width])</span><br><span class="line"></span><br><span class="line"><span class="comment">#后续灰度处理</span></span><br><span class="line">label=<span class="number">1</span>/(label+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#结果可视化</span></span><br><span class="line">plt.imshow(label)</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220227221719584.png" alt="image-20220227221719584"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#图像储存到本地</span></span><br><span class="line">io.imsave(<span class="string">&#x27;result_k3.png&#x27;</span>,label)</span><br><span class="line"></span><br><span class="line"><span class="comment">#改变k值</span></span><br><span class="line">model1=KMeans(n_clusters=<span class="number">4</span>,random_state=<span class="number">0</span>)</span><br><span class="line">model1.fit(x)</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220227221733893.png" alt="image-20220227221733893"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#改变k值</span></span><br><span class="line">model2=KMeans(n_clusters=<span class="number">8</span>,random_state=<span class="number">0</span>)</span><br><span class="line">model2.fit(x)</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220227221744681.png" alt="image-20220227221744681"></p>
<p>由观察可知，k越小的时候，从一个层级到另一个层级过度的较快，轮廓较为清晰，k越大的时候，层级之间的过度较慢，轮廓较为模糊。</p>
<p><strong>异常检测</strong>：根据输入数据，对不匹配预期模式的数据进行识别。</p>
<p><strong>监督式异常检测</strong>：提前使用带“正常”与“异常”标签的数据对模型进行训练，机器基于训练好的模型判断新数据是否为异常数据。</p>
<p><strong>无监督式异常检测</strong>：通过寻找与其他数据最不匹配的实例来检测出未标记测试数据的异常。</p>
<p><strong>数据降维</strong>：在一定的限定条件下，按照一定的规则，尽可能的保留原始数据集重要信息的同时，降低数据集特征的个数。</p>
<p>随着特征数量越来越多，为了避免过拟合，对样本数量的需求会以指数速度增长。</p>
<p>数据降维最常用的方法：<strong>主成分分析(PCA)</strong>,</p>
<p>也称主分量分析，按照一定规则把数据变换到一个新的坐标系统中，使得任何数据<strong>投影</strong>后尽可能可以分开(新数据尽可能不相关，分布方差最大化)。</p>
<p>计算过程：</p>
<ol>
<li>数据预处理(数据分布标准化：u=0，o=1)。</li>
<li>计算协方差矩阵特征向量、及数据在各特征向量投影后的方差。</li>
<li>根据需求(任务指定或方差比例)确定降维维度k。</li>
<li>选取k维特征向量，计算数据在其形成空间的投影。</li>
</ol>
<h4 id="异常消费行为检测："><a href="#异常消费行为检测：" class="headerlink" title="异常消费行为检测："></a>异常消费行为检测：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据加载</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data=pd.read_csv(<span class="string">&#x27;task1_data.csv&#x27;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220305142048582.png" alt="image-20220305142048582"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据可视化</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig1=plt.figure()</span><br><span class="line">plt.scatter(data.loc[:,<span class="string">&#x27;frequency&#x27;</span>],data.loc[:,<span class="string">&#x27;payment&#x27;</span>],marker=<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;raw data&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;frequency&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;payment&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220305143951886.png" alt="image-20220305143951886"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#赋值</span></span><br><span class="line">x=data</span><br><span class="line">x1=data.loc[:,<span class="string">&#x27;frequence&#x27;</span>]</span><br><span class="line">x2=data.loc[:,<span class="string">&#x27;payment&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据分布的可视化操作</span></span><br><span class="line">fig2=plt.figure(figsize=(<span class="number">20</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">fig2_1=plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.hist(x1,bins=<span class="number">100</span>)<span class="comment">#柱状图，切割成100份</span></span><br><span class="line">plt.title(<span class="string">&#x27;frequency data&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;frequency&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;counts&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fig2_2=plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.hist(x2bins=<span class="number">100</span>)<span class="comment">#柱状图，切割成100份</span></span><br><span class="line">plt.title(<span class="string">&#x27;payment data&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;payment&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;counts&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220305223113217.png" alt="image-20220305223113217"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#计算平均值u，以及标准差sigma</span></span><br><span class="line">x1_mean=x1.mean()</span><br><span class="line">x1_sigma=x1.std()</span><br><span class="line"><span class="comment">#x2同理</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#计算基于高斯分布的概率密度函数</span></span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line">x1_range=np.linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">300</span>)<span class="comment">#将0到10分成300份</span></span><br><span class="line">x1_normal=norm.pdf(x1_ramge,x1_mean,x1_sigma)</span><br><span class="line">x2_range=np.linspace(<span class="number">0</span>,<span class="number">400</span>,<span class="number">300</span>)</span><br><span class="line">x2_normal=norm.pdf(x2_range,x2_mean,x2_sigma)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#原始数据的高斯分布概率密度函数的可视化</span></span><br><span class="line">fig3=plt.figure(figsize(<span class="number">20</span>,<span class="number">15</span>))</span><br><span class="line"></span><br><span class="line">fig3_1=plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.plot(x1_range,x1_normal)</span><br><span class="line">plt.title(<span class="string">&#x27;x1(frequency) Gaussian Distribution&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x1(frequency)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;p(x1)&#x27;</span>)</span><br><span class="line"></span><br><span class="line">fig3_2=plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.plot(x2_range,x2_normal)</span><br><span class="line">plt.title(<span class="string">&#x27;x2(payment) Gaussian Distribution&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x2(payment)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;p(x2)&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220305225833616.png" alt="image-20220305225833616"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#建立异常检测模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.covariance <span class="keyword">import</span> EllipticEnvelope</span><br><span class="line">model=EllipticEnvelope(contamination=<span class="number">0.03</span>)</span><br><span class="line">model.fit(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型预测</span></span><br><span class="line">y_predict=model.predict(x)</span><br><span class="line"></span><br><span class="line">plt.scatter(data.loc[:,<span class="string">&#x27;frequency&#x27;</span>][y_predict==<span class="number">1</span>],data.loc[:,<span class="string">&#x27;payment&#x27;</span>][y_predict==<span class="number">1</span>],marker=<span class="string">&#x27;o&#x27;</span>,facecolor=<span class="string">&#x27;none&#x27;</span>,edgecolor=<span class="string">&#x27;red&#x27;</span>,s=<span class="number">150</span>，label=<span class="string">&#x27;anomaly_data&#x27;</span>)<span class="comment">#红色空心和大小</span></span><br><span class="line">plt.legend()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220306134407329.png" alt="image-20220306134407329"></p>
<p><strong>当contamination=0.2时</strong>：</p>
<p><img src="../pictures/image-20220306134836497.png" alt="image-20220306134836497"></p>
<p>由此可见，当阈值增大时，检测出的异常数据的比例也因此增大。</p>
<h4 id="PCA-逻辑回归预测检查者是否患糖尿病"><a href="#PCA-逻辑回归预测检查者是否患糖尿病" class="headerlink" title="PCA+逻辑回归预测检查者是否患糖尿病"></a>PCA+逻辑回归预测检查者是否患糖尿病</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据加载</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data=pd.read_csv(<span class="string">&#x27;task2_data.csv&#x27;</span>)</span><br><span class="line">data.head()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220306162432375.png" alt="image-20220306162432375"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#赋值</span></span><br><span class="line">x=data.drop([<span class="string">&#x27;label&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">y=data.loc[:,<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#逻辑回归模型</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">model1=LogisticRegression(max_iter=<span class="number">1000</span>)<span class="comment">#更新最大迭代次数</span></span><br><span class="line">model1.fit(x,y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#结果预测</span></span><br><span class="line">y_predict=model1.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型评估</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">accuracy=accutacy_score(y,y_predict)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.precessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">x_norm=StandardScaler().fit_transform(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算均值与标准差</span></span><br><span class="line">x1_mean=x.loc[:,<span class="string">&#x27;glucise&#x27;</span>].mean()</span><br><span class="line">x1_norm_mean=x_norm[:,<span class="number">1</span>].mean()<span class="comment">#取第二列，坐标为1，因为格式变化，所以索引方式不同</span></span><br><span class="line">x1_sigma=x.loc[:,<span class="string">&#x27;glucose&#x27;</span>].std()</span><br><span class="line">x1_norm_sigma=x_norm[:,<span class="number">1</span>].std()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#可视化</span></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig1=plt.figure(figsize=(<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">fig1_1=plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.hist(x.loc[:,<span class="string">&#x27;glucose&#x27;</span>],bins=<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">fig1_2=plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.hist(x_norm[:,<span class="number">1</span>],bins=<span class="number">100</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220306164900034.png" alt="image-20220306164900034"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#pca分析</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca=PCA(n_components=<span class="number">8</span>)</span><br><span class="line">x_pca=pca.fit_transform(x_form)</span><br><span class="line"><span class="comment">#计算分析后各成分的方差以及方差比例</span></span><br><span class="line">var=pca.explained_variance_</span><br><span class="line">var_ratio=pca.explained_variance_ratio_</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#可视化方差比例</span></span><br><span class="line">fig2=plt.figure(figsize=(<span class="number">10</span>,<span class="number">5</span>))</span><br><span class="line">plt.bar([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>],var_ratio)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220306183137392.png" alt="image-20220306183137392"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据降维到2维</span></span><br><span class="line">pca=PCA(n_components=<span class="number">2</span>)</span><br><span class="line">x_pca=pca.fit_transform(x_norm)</span><br><span class="line"><span class="built_in">print</span>(x_pca.shape,x_norm.shape)</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220306185414925.png" alt="image-20220306185414925"></p>
<p>由此可见，通过pca将原本八维的数据降维成了二维。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#降维数据的可视化</span></span><br><span class="line">fig3=plt.figure()</span><br><span class="line">plt.scatter(x_pca[:,<span class="number">1</span>][y==<span class="number">0</span>],x_pca[:,<span class="number">1</span>][y==<span class="number">0</span>],marker=<span class="string">&#x27;x&#x27;</span>,label=<span class="string">&#x27;negative&#x27;</span>)</span><br><span class="line">plt.scatter(x_pca[:,<span class="number">1</span>][y==<span class="number">1</span>],x_pca[:,<span class="number">1</span>][y==<span class="number">1</span>],marker=<span class="string">&#x27;*&#x27;</span>,label=<span class="string">&#x27;positive&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="../pictures/image-20220306193036424.png" alt="image-20220306193036424"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#降维后的模型建立与训练</span></span><br><span class="line">model2=LogisticRegression()</span><br><span class="line">model2.fit(x_pca,y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#模型预测</span></span><br><span class="line">y_predict_pca=model2.predict(x_pca)</span><br><span class="line">accuracy_pca=accuracy_score(y,y_predict_pca)</span><br></pre></td></tr></table></figure>

</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Jerry Ren</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/02/24/More-For-Machine-Learning/">http://example.com/2022/02/24/More-For-Machine-Learning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="next-post pull-right"><a href="/2022/02/09/Start-Up-For-Machine-Learning/"><span>Start Up For Machine Learning</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fimg.jj20.com%2Fup%2Fallimg%2F1114%2F123020113951%2F201230113951-1-1200.jpg&amp;refer=http%3A%2F%2Fimg.jj20.com&amp;app=2002&amp;size=f9999,10000&amp;q=a80&amp;n=0&amp;g=0n&amp;fmt=jpeg?sec=1644738157&amp;t=0a3e38ccf19424d69fb8678eb1bf7a75.jpg)"><div class="layout" id="footer"><div class="copyright">&copy;2021 - 2022 By Jerry Ren</div><div class="framework-info"><span>Driven - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" data-click="false"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>